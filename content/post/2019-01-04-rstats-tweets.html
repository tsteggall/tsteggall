---
title: "#Rstats Tweets"
subtitle: "#TidyTuesday 2019 Week 1"
authors: ["admin"]
date: '2019-01-04'
slug: rstats-tweets
categories: ["RStats"]
tags: ["#TidyTuesday"]
---



<p>Happy New Year! This first TidyTuesday dataset of 2019 was a great way to get the year started. I’ve been working on a separate side project that will include analyzing social media trends, so I thought this would be a good opportunity to test out at least one rough idea I’ve been kicking around.</p>
<p>I wanted to plot the most popular topics (as measured by word/token frequency) chronologically, to see if any particular keywords were unique to certain timeframes, and/or their frequency of use stood out. As I worked through this I had even more ideas about how to improve this in the future (anomaly detection?), but the primary goal was to find a rough method to detect certain events or issues that popped up over the course of 2018 #rstats tweets.</p>
<div id="setup" class="section level3">
<h3>Setup</h3>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(tidytext)

theme_set(theme_light())</code></pre>
</div>
<div id="data" class="section level3">
<h3>Data</h3>
<pre class="r"><code># I saw this method of importing the data in a couple other users TidyTuesday posts, but for some reason this didn&#39;t work for me, so I manually downloaded the data.

##download.file(&quot;https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-01/rstats_tweets.rds&quot;, &quot;rstats_tweets.rds&quot;)

##tweets_raw &lt;- read_rds(&quot;rstats_tweets.rds&quot;)

tweets_raw &lt;- read_rds(&quot;~/Data/TidyTuesday/rstats_tweets.rds&quot;)</code></pre>
<p>Based on my idea above, the actual number of columns I’ll need is much less than the 88 provided. I’m also only going to include tweets from 2018.</p>
<pre class="r"><code>tweets_simple &lt;- tweets_raw %&gt;%
  dplyr::select(created_at, screen_name, text) %&gt;%
  filter(year(created_at) == 2018) %&gt;%
  mutate(week = week(created_at)) %&gt;%
  arrange(created_at)

head(tweets_simple, n = 10)</code></pre>
<pre><code>## # A tibble: 10 x 4
##    created_at          screen_name  text                               week
##    &lt;dttm&gt;              &lt;chr&gt;        &lt;chr&gt;                             &lt;dbl&gt;
##  1 2018-01-01 00:04:21 Cruz_Julian_ Rbloggers Data science courses i~     1
##  2 2018-01-01 00:08:03 d_olivaw     &quot;So now I&#39;ve got 1 warning and s~     1
##  3 2018-01-01 00:22:03 znmeb        R Interface to Python • reticula~     1
##  4 2018-01-01 00:24:37 fossilosophy &quot;Finishing out the year with som~     1
##  5 2018-01-01 00:26:37 Mooniac      Not usually a fan of Cheat-sheet~     1
##  6 2018-01-01 00:30:19 Mooniac      Just the thing, instant clumping~     1
##  7 2018-01-01 00:31:39 hrbrmstr     &quot;So #rstats…let me clarify that ~     1
##  8 2018-01-01 00:40:44 Mooniac      @fossilosophy Thought #rstats mi~     1
##  9 2018-01-01 00:41:42 fossilosophy @Mooniac I think it&#39;s a smallish~     1
## 10 2018-01-01 00:42:26 DaveQuartey  &quot;In no order: Partipated in Hack~     1</code></pre>
<p>For cleaning the text of the tweets, I leaned heavily on <a href="https://www.tidytextmining.com/twitter.html">Julia Silge’s TidyText</a>. This is an amazing resource and one I imagine I’ll continue to reference going forward.</p>
<p>After some trial and error, I decided to remove certain words because they overwhelmed my plot (I realized after the fact that there are probably better ways around this issue than just removing them, but I’ll save that for next time). Removing “#rstats” made sense initially, but then I decided to remove the rest of the words in the final filter argument below. This was not at all scientific, and is any area to improve going forward.</p>
<pre class="r"><code>remove_reg &lt;- &quot;&amp;amp;|&amp;lt;|&amp;gt;&quot;

tidy_tweets &lt;- tweets_simple %&gt;% 
  filter(!str_detect(text, &quot;^RT&quot;)) %&gt;%
  mutate(text = str_remove_all(text, remove_reg)) %&gt;%
  unnest_tokens(word, text, token = &quot;tweets&quot;) %&gt;%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, &quot;&#39;&quot;),
         str_detect(word, &quot;[a-z]&quot;),
         !word %in% c(&quot;#rstats&quot;, &quot;#datascience&quot;, &quot;data&quot;, &quot;#tidyverse&quot;, &quot;package&quot;, 
                      &quot;cran&quot;,&quot;#bigdata&quot;, &quot;#python&quot;, &quot;#machinelearning&quot;, &quot;#dataviz&quot;,
                      &quot;#analytics&quot;, &quot;code&quot;))

head(tidy_tweets, n = 10)</code></pre>
<pre><code>## # A tibble: 10 x 4
##    created_at          screen_name   week word                   
##    &lt;dttm&gt;              &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;                  
##  1 2018-01-01 00:04:21 Cruz_Julian_     1 rbloggers              
##  2 2018-01-01 00:04:21 Cruz_Julian_     1 science                
##  3 2018-01-01 00:04:21 Cruz_Julian_     1 courses                
##  4 2018-01-01 00:04:21 Cruz_Julian_     1 udemy                  
##  5 2018-01-01 00:04:21 Cruz_Julian_     1 sale                   
##  6 2018-01-01 00:04:21 Cruz_Julian_     1 https://t.co/lqtzzxkkuy
##  7 2018-01-01 00:08:03 d_olivaw         1 warning                
##  8 2018-01-01 00:08:03 d_olivaw         1 notes                  
##  9 2018-01-01 00:08:03 d_olivaw         1 treat                  
## 10 2018-01-01 00:08:03 d_olivaw         1 s3</code></pre>
<p>I decided to only to plot the top 3 topics of conversation per week from 2018, and only label <em>unique</em> topics to help keep the plot a bit cleaner.</p>
<pre class="r"><code>weekly_topics &lt;- tidy_tweets %&gt;%
  dplyr::select(week, word) %&gt;%
  count(week, word) %&gt;%
  group_by(week) %&gt;%
  top_n(n = 3, wt = n) %&gt;%
  mutate(rank = order(order(n, decreasing=TRUE)))
  
weekly_topics$unique &lt;- duplicated(weekly_topics$word) | duplicated(weekly_topics$word, fromLast = TRUE)


top_n(weekly_topics, 10)</code></pre>
<pre><code>## # A tibble: 159 x 5
## # Groups:   week [51]
##     week word              n  rank unique
##    &lt;dbl&gt; &lt;chr&gt;         &lt;int&gt; &lt;int&gt; &lt;lgl&gt; 
##  1     1 #ai              83     1 TRUE  
##  2     1 #iot             75     3 TRUE  
##  3     1 #tech            76     2 TRUE  
##  4     2 #iot             94     1 TRUE  
##  5     2 #tech            91     3 TRUE  
##  6     2 rbloggers        94     2 TRUE  
##  7     3 rbloggers        91     1 TRUE  
##  8     3 updates          84     2 TRUE  
##  9     3 version          83     3 TRUE  
## 10     4 #deeplearning    93     3 FALSE 
## # ... with 149 more rows</code></pre>
</div>
<div id="plot" class="section level3">
<h3>Plot</h3>
<pre class="r"><code>weekly_topics %&gt;%
  ggplot(aes(week, n)) +
  geom_jitter() +
  geom_text(aes(label=ifelse(unique == FALSE, as.character(word),&#39;&#39;), 
                hjust=-0.2, vjust=0.1), color=&quot;red&quot;, size = 3.5, 
            check_overlap = FALSE) +
  labs(x = &quot;Week&quot;, y = &quot;Frequency of Word&quot;, title = &quot;2018 Most Tweeted Topics in 
       #rstats Tweets&quot;)</code></pre>
<p><img src="/post/2019-01-04-rstats-tweets_files/figure-html/topics%20plot-1.png" width="672" /></p>
<p>This isn’t the prettiest graph in the world, but it accomplishes what I set out to do by highlighting a few time-specific events, like the #rstudioconf and the useR! 2018 conference. This was a solid introduction to working with Twitter data, and gave me plenty of ideas on how to improve my analysis going forward. Success!</p>
</div>
<div id="resources" class="section level3">
<h3>Resources</h3>
<p>I wanted to highlight and link to a couple of the resources I used while working on this. These helped generate some ideas and get through a couple of the trickier spots.</p>
<p><a href="https://www.tidytextmining.com/twitter.html">Julia Silge and David Robinson’s Text Mining with R</a> - an amazing and FREE resource that walks through a tidy approach to text mining in R. Unbelievably helpful with 3 case study examples, including one that analyzes Twitter archives. Could not have done this analysis without this as a guide.</p>
<p><a href="https://stackoverflow.com/questions/32150213/test-if-a-value-is-unique-in-a-vector-in-r">Stack Overflow - Test if a value is unique in a vector in R</a> - when I realized I wanted to highlight only unique labels, I need this to figure out how to identify the unique values in weekly_topics$word.</p>
</div>
